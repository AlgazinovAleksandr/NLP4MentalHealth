{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b129b43",
   "metadata": {},
   "source": [
    "### Про метрику\n",
    "\n",
    "Важной частью этого чекпоинта является выбор метрики. Напомним, что на текущий момент видение проекта - LLM / Agent-based ассистент для задач ментального здоровья. То есть в качестве стандартных NLP-метрик необходимо использовать метрики для задачи Language Modeling / текстовой генерации, такие как вывод обученной reward-модели, perplexity, side-by-side сравнение на асессорах, и так далее. При этом для ML-бейзлайна на текущем этапе мы будем решать задачу текстовой классификации. Для этой задачи мы можем использовать классические метрики для текстовой классификации, такие как accuracy, precision, recall, F1-score, и так далее. При этом у нас нет негативых сэмплов, так как каждое наблюдение принадлежит какому-то классу, связанного с ментальным здоровьем. Поэтому будем использовать просто accuracy (сбалансированную по классам, так как датасет является не супер сбалансированным)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f9e97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c50bbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of reddit_df:  151288\n",
      "len of reddit_df after dropna:  148936\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>get extremely anxious ’ working 247</td>\n",
       "      <td>month ago accepted full time software engineer...</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cant clean house feel incredibly motivated cle...</td>\n",
       "      <td>hey guy curious anyone else issue apartment fu...</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>need help</td>\n",
       "      <td>6 exam next 2 week one monday havent studied f...</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anyone chat</td>\n",
       "      <td>anyone struggling addadhd ’ interesting chatti...</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>figuring eat suck</td>\n",
       "      <td>whenever get hungry never eat dont know eat en...</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                get extremely anxious ’ working 247   \n",
       "1  cant clean house feel incredibly motivated cle...   \n",
       "2                                          need help   \n",
       "3                                        anyone chat   \n",
       "4                                  figuring eat suck   \n",
       "\n",
       "                                                body target  \n",
       "0  month ago accepted full time software engineer...   ADHD  \n",
       "1  hey guy curious anyone else issue apartment fu...   ADHD  \n",
       "2  6 exam next 2 week one monday havent studied f...   ADHD  \n",
       "3  anyone struggling addadhd ’ interesting chatti...   ADHD  \n",
       "4  whenever get hungry never eat dont know eat en...   ADHD  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# нанов в процентах немного, а данных много, поэтому позволим себе просто удалить наны на текущем этапе\n",
    "reddit_df = pd.read_csv('../data/reddit_mental_health_posts_preprocessed.csv')\n",
    "reddit_df = reddit_df[['title', 'body', 'subreddit']]\n",
    "reddit_df = reddit_df.rename(columns={'subreddit': 'target'})\n",
    "print('len of reddit_df: ', len(reddit_df))\n",
    "reddit_df = reddit_df.dropna()\n",
    "print('len of reddit_df after dropna: ', len(reddit_df))\n",
    "reddit_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03bcc142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCD           41812\n",
       "ADHD          37058\n",
       "depression    23770\n",
       "ptsd          23758\n",
       "aspergers     22538\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# видно, что датасет не супер сбалансирован\n",
    "reddit_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392397c",
   "metadata": {},
   "source": [
    "### Соединим title и body, и построим эмбеддинги\n",
    "\n",
    "Для сравнения будем использовать:\n",
    "\n",
    "+ tf-idf\n",
    "\n",
    "+ tf-idf + SVD разложение (понижение размерности)\n",
    "\n",
    "+ Word2Vec с усреднением эмбеддингов по словам\n",
    "\n",
    "+ Простенький трансформер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a4f18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADHD</td>\n",
       "      <td>Title: get extremely anxious ’ working 247; Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADHD</td>\n",
       "      <td>Title: cant clean house feel incredibly motiva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADHD</td>\n",
       "      <td>Title: need help; Body: 6 exam next 2 week one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADHD</td>\n",
       "      <td>Title: anyone chat; Body: anyone struggling ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADHD</td>\n",
       "      <td>Title: figuring eat suck; Body: whenever get h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0   ADHD  Title: get extremely anxious ’ working 247; Bo...\n",
       "1   ADHD  Title: cant clean house feel incredibly motiva...\n",
       "2   ADHD  Title: need help; Body: 6 exam next 2 week one...\n",
       "3   ADHD  Title: anyone chat; Body: anyone struggling ad...\n",
       "4   ADHD  Title: figuring eat suck; Body: whenever get h..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df['text'] = 'Title: ' + reddit_df['title'] + '; Body: ' + reddit_df['body']\n",
    "reddit_df = reddit_df.drop(['title', 'body'], axis=1)\n",
    "reddit_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4ea2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec7d5c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(df):\n",
    "    results = []\n",
    "    df1 = df.copy()\n",
    "    df2 = df.copy()\n",
    "    df3 = df.copy()\n",
    "    df4 = df.copy()\n",
    "    # Let's start with tf-idf embeddings\n",
    "    print(\"Creating tf-idf embeddings\")\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "    X_tfidf = tfidf_vectorizer.fit_transform(df1['text']).toarray()\n",
    "    results.append((df1, \"tf-idf\", X_tfidf))\n",
    "    \n",
    "    # Now let's add SVD to serve as dimensionality reduction\n",
    "    print(\"Creating tf-idf + SVD embeddings\")\n",
    "    svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "    X_tfidf_svd = svd.fit_transform(X_tfidf)\n",
    "    results.append((df2, \"tf-idf+SVD\", X_tfidf_svd))\n",
    "    \n",
    "    # Time to do something more advanced - shall we use transformers?\n",
    "    print(\"Creating Sentence-BERT embeddings\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2') # something lightweight so that the laptop does not die\n",
    "    sentences = df3['text'].tolist()\n",
    "    X_sbert = model.encode(sentences, batch_size=32, show_progress_bar=True)\n",
    "    results.append((df3, \"Sentence-BERT\", X_sbert))\n",
    "    \n",
    "    # Word2Vec with averaging is not dead, is it?\n",
    "    print(\"Creating Word2Vec embeddings\")\n",
    "    tokenized_texts = [word_tokenize(text.lower()) for text in df4['text']]\n",
    "    w2v_model = Word2Vec(\n",
    "        sentences=tokenized_texts,\n",
    "        vector_size=128,\n",
    "        window=5,\n",
    "        min_count=5,\n",
    "        workers=4,\n",
    "        seed=42\n",
    "    )\n",
    "    # Averaging word vectors\n",
    "    doc_vectors = []\n",
    "    for doc in tokenized_texts:\n",
    "        word_vecs = [w2v_model.wv[word] for word in doc if word in w2v_model.wv]\n",
    "        if len(word_vecs) > 0:\n",
    "            doc_vectors.append(np.mean(word_vecs, axis=0))\n",
    "        else:\n",
    "            doc_vectors.append(np.zeros(w2v_model.vector_size))\n",
    "    X_word2vec = np.array(doc_vectors)\n",
    "    results.append((df4, \"Word2Vec\", X_word2vec))\n",
    "    \n",
    "    print('Success')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7bc2cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tf-idf embeddings\n",
      "Creating tf-idf + SVD embeddings\n",
      "Creating Sentence-BERT embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(85585) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbf7d2ed424435780c7eacc2e81d2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27349f748ad54217a681261ebdd560e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4655 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Word2Vec embeddings\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "embedding_df = create_embeddings(reddit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8d352a",
   "metadata": {},
   "source": [
    "### Начнем моделировать. Для каждого из эмбеддингов построим 4 модели:\n",
    "\n",
    "+ Logistic Regression\n",
    "\n",
    "+ KNN\n",
    "\n",
    "+ CatBoost\n",
    "\n",
    "+ MLP (простой MLP из sklearn)\n",
    "\n",
    "После этого измерим качество моделей на тестовой выборке и выберем лучшую. Будем выбирать по balanced accuracy, а выборку будем делить на трейн и тест в соотношении 90:10 (для CatBoost и MLP будем использовать дополнительную валидационную выборку)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e2e9300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f08b1f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test, embedding_name, model_name, \n",
    "                             X_val=None, y_val=None):\n",
    "    \n",
    "    if model_name == \"Logistic Regression\":\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "    elif model_name == \"CatBoost\":\n",
    "        if X_val is not None and y_val is not None:\n",
    "            model = CatBoostClassifier(\n",
    "                random_state=42,\n",
    "                verbose=False,\n",
    "                early_stopping_rounds=20\n",
    "            )\n",
    "            model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "        else:\n",
    "            model = CatBoostClassifier(random_state=42, verbose=False)\n",
    "            model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "    elif model_name == \"KNN\":\n",
    "        model = KNeighborsClassifier(n_neighbors=16) # 2 ** 4\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "    elif model_name == \"MLP\":\n",
    "        model = MLPClassifier(\n",
    "            hidden_layer_sizes=(128, 64),\n",
    "            random_state=42,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.05,\n",
    "            max_iter=100\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25110ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tf-idf+SVD\n",
      "Train shape: (125999, 300), Val shape: (8043, 300), Test shape: (14894, 300)\n",
      "Training Logistic Regression\n",
      "tf-idf+SVD + Logistic Regression: 0.7457\n",
      "Training CatBoost\n",
      "tf-idf+SVD + CatBoost: 0.7432\n",
      "Training KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(89726) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf+SVD + KNN: 0.5836\n",
      "Training MLP\n",
      "tf-idf+SVD + MLP: 0.7561\n",
      "Processing Sentence-BERT\n",
      "Train shape: (125999, 384), Val shape: (8043, 384), Test shape: (14894, 384)\n",
      "Training Logistic Regression\n",
      "Sentence-BERT + Logistic Regression: 0.7472\n",
      "Training CatBoost\n",
      "Sentence-BERT + CatBoost: 0.7493\n",
      "Training KNN\n",
      "Sentence-BERT + KNN: 0.7282\n",
      "Training MLP\n",
      "Sentence-BERT + MLP: 0.7622\n",
      "Processing Word2Vec\n",
      "Train shape: (125999, 128), Val shape: (8043, 128), Test shape: (14894, 128)\n",
      "Training Logistic Regression\n",
      "Word2Vec + Logistic Regression: 0.6849\n",
      "Training CatBoost\n",
      "Word2Vec + CatBoost: 0.6905\n",
      "Training KNN\n",
      "Word2Vec + KNN: 0.5975\n",
      "Training MLP\n",
      "Word2Vec + MLP: 0.7131\n"
     ]
    }
   ],
   "source": [
    "models = [\"Logistic Regression\", \"CatBoost\", \"KNN\", \"MLP\"]\n",
    "results = []\n",
    "\n",
    "for df_copy, embedding_name, X_embeddings in embedding_df:\n",
    "    if embedding_name == \"tf-idf\": # неудачная размерность 5000, все слишком долго обучалось и я решил выкинуть обычный tf-idf из анализа\n",
    "        continue\n",
    "    print(f\"Processing {embedding_name}\")\n",
    "    y = df_copy['target'].values\n",
    "    # Везде будет одинаковая тестовая выборка даже при условии, что валидационную использует по сути только CatBoost\n",
    "    # А нейронка делает валидационную саму из трейновой выборке. Это не супер корректно, но мб кто-то это когда-то поправит :)\n",
    "    # Но в целом и так не критично, у нас же бейзлайн\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X_embeddings, y, test_size=0.1, random_state=42, stratify=y\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.06, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    print(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}, Test shape: {X_test.shape}\")\n",
    "    \n",
    "    for model_name in models:\n",
    "        print(f\"Training {model_name}\")\n",
    "        if model_name in [\"CatBoost\"]:\n",
    "            accuracy = train_and_evaluate_models(\n",
    "                X_train, X_test, y_train, y_test, embedding_name, model_name, X_val, y_val\n",
    "            )\n",
    "        else:\n",
    "            accuracy = train_and_evaluate_models(\n",
    "                X_train, X_test, y_train, y_test, embedding_name, model_name\n",
    "            )\n",
    "        results.append({\n",
    "            'Embedding': embedding_name,\n",
    "            'Model': model_name,\n",
    "            'Balanced_Accuracy': accuracy\n",
    "        })\n",
    "        print(f\"{embedding_name} + {model_name}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2df56ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "pivot_results = results_df.pivot_table(\n",
    "        index='Embedding', \n",
    "        columns='Model', \n",
    "        values='Balanced_Accuracy'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dddb7e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embedding</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence-BERT</th>\n",
       "      <td>0.749341</td>\n",
       "      <td>0.728169</td>\n",
       "      <td>0.747167</td>\n",
       "      <td>0.762219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec</th>\n",
       "      <td>0.690497</td>\n",
       "      <td>0.597548</td>\n",
       "      <td>0.684865</td>\n",
       "      <td>0.713112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf+SVD</th>\n",
       "      <td>0.743215</td>\n",
       "      <td>0.583596</td>\n",
       "      <td>0.745709</td>\n",
       "      <td>0.756078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model          CatBoost       KNN  Logistic Regression       MLP\n",
       "Embedding                                                       \n",
       "Sentence-BERT  0.749341  0.728169             0.747167  0.762219\n",
       "Word2Vec       0.690497  0.597548             0.684865  0.713112\n",
       "tf-idf+SVD     0.743215  0.583596             0.745709  0.756078"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff12ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_results.to_csv('reddit_baseline_results_balanced_accuracy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe4160c",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "+ MLP (на удивление) оказалась и самой сильной, и самой устойчивой моделью. В отличие от всех других моделей, здесь качество (в виде balanced accuracy) на тестовой выборке не опустилось ниже 0.7\n",
    "\n",
    "+ KNN проигрывает всем моделям на всех эмбеддингах, единственный показал качество ниже 0.6. Это значительно хуже других моделей\n",
    "\n",
    "+ Он же (KNN) оказался самым неустойчивым, где разброс между лучшей и худшей моделью превышает 0.1 (во всех остальных моделях спред в районе 0.05)\n",
    "\n",
    "+ Несмотря на кардинально разные алгоритмы и структуры моделей, CatBoost и LogReg ведут себя удивительно схоже с точки зрения качества\n",
    "\n",
    "+ Хоть мы и обучили немного всего, это честный труд :) А еще мы получили на удивление действительно интересные результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425cbe83",
   "metadata": {},
   "source": [
    "### Возможный (и желательный) TODO:\n",
    "\n",
    "+ Пофиксить логику с валидационной выборкой. Пусть она создается не везде, а только там, где нужно, чтобы не терять данные\n",
    "\n",
    "+ Измерить больше метрик, построить confusion матрицы\n",
    "\n",
    "+ Выбрать лучшую модель (например, CatBoost / MLP на Sentence-BERT эмбеддингах), потюнить ее гиперпараметры, и посмотреть, как будет меняться качество. Выбрать лучшие гиперпараметры, и замерить финальное качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1704c3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
